{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a078071-3cb1-4278-b375-5c45efa100ca",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>基于pytorch + LSTM 的古诗生成</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d209d-b78d-4244-acf5-116462793004",
   "metadata": {},
   "source": [
    "### 作业介绍: \n",
    "本课程使用pytorch框架, 完成NLP任务:古诗生成,使用的模型为 LSTM, 并训练了词向量, 支持随机古诗和藏头诗生成, 并且生成的古诗具有多变性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea3e70-08b6-4758-971b-4f2d2807b906",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecdbbb6-e8ef-4d71-8aec-b6b30e3bcd4b",
   "metadata": {},
   "source": [
    "### 导包:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d162c71c-6dca-4c4a-830a-4e3e73a9dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\QUE\\.conda\\envs\\nndl\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a9016-fe98-44ed-988c-ae8a42e4f741",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2a818-a853-4fe8-a35d-ffa346d09202",
   "metadata": {},
   "source": [
    "### 生成切分文件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f00d6c-e537-478c-88b7-b273a121ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(file=\"poetry_7.txt\", train_num=6000):\n",
    "    all_data = open(file, \"r\", encoding=\"utf-8\").read()\n",
    "    with open(\"split_7.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        split_data = \" \".join(all_data)\n",
    "        f.write(split_data)\n",
    "    return split_data[:train_num * 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a29d1e-73cf-4430-b4e1-78b516ffcd23",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d6941-ef95-4dc2-a528-f8e3c2020df0",
   "metadata": {},
   "source": [
    "### 训练词向量:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0814c1-bfcd-42fe-9a67-95e5bc1a1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vec(split_file=\"split_7.txt\", org_file=\"poetry_7.txt\", train_num=6000):\n",
    "    param_file = \"word_vec.pkl\"\n",
    "    org_data = open(org_file, \"r\", encoding=\"utf-8\").read().split(\"\\n\")[:train_num]\n",
    "    if os.path.exists(split_file):\n",
    "        all_data_split = open(split_file, \"r\", encoding=\"utf-8\").read().split(\"\\n\")[:train_num]\n",
    "    else:\n",
    "        all_data_split = split_text().split(\"\\n\")[:train_num]\n",
    "\n",
    "    if os.path.exists(param_file):\n",
    "        return org_data, pickle.load(open(param_file, \"rb\"))\n",
    "\n",
    "    models = Word2Vec(all_data_split, vector_size=128, workers=7, min_count=1)\n",
    "    pickle.dump([models.syn1neg, models.wv.key_to_index, models.wv.index_to_key], open(param_file, \"wb\"))\n",
    "    return org_data, (models.syn1neg, models.wv.key_to_index, models.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eea4ec-a0e2-4857-aea9-5078e9aaeed2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bbc2b-57e1-4cef-a9e7-92eced1879e7",
   "metadata": {},
   "source": [
    "### 构建数据集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c761d3-8d79-4a9f-b208-4685e8593c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poetry_Dataset(Dataset):\n",
    "    def __init__(self, w1, word_2_index, all_data):\n",
    "        self.w1 = w1\n",
    "        self.word_2_index = word_2_index\n",
    "        self.all_data = all_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        a_poetry = self.all_data[index]\n",
    "\n",
    "        a_poetry_index = [self.word_2_index[i] for i in a_poetry]\n",
    "        xs = a_poetry_index[:-1]\n",
    "        ys = a_poetry_index[1:]\n",
    "        xs_embedding = self.w1[xs]\n",
    "\n",
    "        return xs_embedding, np.array(ys).astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53b25d-7c27-46e9-9ed5-eeece1868313",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873af03-36bb-44a5-9f24-7a16cb1be51c",
   "metadata": {},
   "source": [
    "### 模型构建:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32e517d-646b-431d-9eb3-a74edc06bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poetry_Model_lstm(nn.Module):\n",
    "    def __init__(self, hidden_num, word_size, embedding_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        ######定义模型######\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, xs_embedding, h_0=None, c_0=None):\n",
    "        if h_0 == None or c_0 == None:\n",
    "            h_0 = torch.tensor(np.zeros((2, xs_embedding.shape[0], self.hidden_num), dtype=np.float32))\n",
    "            c_0 = torch.tensor(np.zeros((2, xs_embedding.shape[0], self.hidden_num), dtype=np.float32))\n",
    "        h_0 = h_0.to(self.device)\n",
    "        c_0 = c_0.to(self.device)\n",
    "        xs_embedding = xs_embedding.to(self.device)\n",
    "        ######定义模型######\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        return pre, (h_0, c_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70194fcf-7012-467a-b8bb-1cb1d92ef28b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c499f-551e-4a5a-9464-644f2e05f143",
   "metadata": {},
   "source": [
    "### 自动生成古诗:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70bd6aa6-6e97-4f73-8629-abbf13184f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poetry_auto():\n",
    "    result = \"\"\n",
    "    word_index = np.random.randint(0, word_size, 1)[0]\n",
    "\n",
    "    result += index_2_word[word_index]\n",
    "    h_0 = torch.tensor(np.zeros((2, 1, hidden_num), dtype=np.float32))\n",
    "    c_0 = torch.tensor(np.zeros((2, 1, hidden_num), dtype=np.float32))\n",
    "\n",
    "    for i in range(31):\n",
    "        word_embedding = torch.tensor(w1[word_index][None][None])\n",
    "        pre, (h_0, c_0) = model(word_embedding, h_0, c_0)\n",
    "        word_index = int(torch.argmax(pre))\n",
    "        result += index_2_word[word_index]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33901082-0b12-4a85-a523-0b9745668be9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04be6a-9eaa-440b-9ea3-25a4f9a6eb48",
   "metadata": {},
   "source": [
    "### 藏头诗生成:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75beb453-4ced-48cb-867d-9d3a862f99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poetry_acrostic():\n",
    "    input_text = input(\"请输入四个汉字：\")[:4]\n",
    "    result = \"\"\n",
    "    punctuation_list = [\"，\", \"。\", \"，\", \"。\"]\n",
    "    for i in range(4):\n",
    "        result += input_text[i]\n",
    "        h_0 = torch.tensor(np.zeros((2, 1, hidden_num), dtype=np.float32))\n",
    "        c_0 = torch.tensor(np.zeros((2, 1, hidden_num), dtype=np.float32))\n",
    "        word = input_text[i]\n",
    "        for j in range(6):\n",
    "            word_index = word_2_index[word]\n",
    "            word_embedding = torch.tensor(w1[word_index][None][None])\n",
    "            pre , (h_0,c_0) = model(word_embedding,h_0,c_0)\n",
    "            word = index_2_word[int(torch.argmax(pre))]\n",
    "            result += word\n",
    "        result+=punctuation_list[i]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23dabc-7c12-453c-b3ce-f2d66f10b5bc",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581610cc-ea20-4484-93cb-e01d3c4048f4",
   "metadata": {},
   "source": [
    "### 主函数: 定义参数, 模型, 优化器, 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8638fa48-fbc5-44fa-b127-900567d1d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:7.710\n",
      "季火载火载火。。。火。。。载。。。。。。，。。。。。。，，。。。\n",
      "loss:6.969\n",
      "窅，。，。，，。。，。。，，。。，。。，，，，，，，，，。，，，\n",
      "loss:6.843\n",
      "启，。，。。。，，。。，。。，，，。，。。。。。。。。。。。。，\n",
      "loss:6.745\n",
      "奇，，，，，，，，，，，，，，。，。，，。，，，，，。，，，，，\n",
      "loss:6.695\n",
      "大山山山，山，，，，，，，，。。，，，，，，。，，，。，。，，。\n",
      "loss:6.598\n",
      "译山三风，日山，三光，三三，山，三三，山，山山，三三，山三，日山\n",
      "loss:6.529\n",
      "复台山三，，山，，山，，海，，海，，，山，山，，海，海，，，海，\n",
      "loss:6.372\n",
      "椰人山光海海，，一不，海，海海，，海，海，海，天，海海，，，海海\n",
      "loss:6.286\n",
      "洵色风三海海，，一一，一一，，，一，，一，。，，天，，，一，一，\n",
      "loss:6.174\n",
      "端花三光海天，一山不一天，一，一一。一天。一。山天山，一。一一天\n",
      "loss:6.027\n",
      "闹山风海生生，，山不天无天。。山不山不。无。一天无无。一。一一天\n",
      "loss:5.996\n",
      "柁门烟路六三天，一来一山无公。。今一一花无水。一来一山一。。一一\n",
      "loss:5.859\n",
      "摇阙风山海斗，，海山一山不。。海山一一不。。海来一山不天。一里一\n",
      "loss:5.800\n",
      "孙有无路海远，，海风一来不。。一山烟花不中，。来烟山一水。。海春\n",
      "loss:5.723\n",
      "脱来风气都水，，一天烟山一天。。海山烟山无来。。海风风一天青。一\n",
      "loss:5.658\n",
      "锐花梅结六天天，一山一花一战。。一山一影一染花。一山一风一天，，\n",
      "loss:5.610\n",
      "金门风光六天有，金来编蕉一天香。一来一山一天。，山天风日一中，一\n",
      "loss:5.552\n",
      "经色风路一氏迈，一山一望一色吟。一是一风不人。，山风人一天花。一\n",
      "loss:5.517\n",
      "然秋若气斗天席，一山烟香一公。。海烟山一人花。一来不山一时花。一\n",
      "loss:5.493\n",
      "心人梅路倏有，海山不溪不无深。一知一风一水。，海不人回无心。一是\n",
      "loss:5.457\n",
      "荡榜下路斗生缪，一锁一山不超端。一来一人一无新。一里一山一无花。\n",
      "loss:5.415\n",
      "廨人三桑暗天天，一章如咏一水香。海须一风一天花。海来一望不无花。\n",
      "loss:5.402\n",
      "荻色高光斗水，，山不山旧相端。一来一水一天人。一来一年一无来，一\n",
      "loss:5.381\n",
      "濴榜三车海峰履，一将不溪一天中。一来一斜一无来。海里一年一野。，\n",
      "loss:5.342\n",
      "消门烟檄三绩，空中无新花一林。一山一护一人。。山风烟声一无花。一\n",
      "loss:5.307\n",
      "垄峰下结都自，，衔衔人咏一精中。一到一时一无来，一来一年不染花，\n",
      "loss:5.286\n",
      "摩榜喧光庆澄，一湾天溪一天深。一山一山一子。白山烟风一时花。一是\n",
      "loss:5.282\n",
      "燃门烟光都生城，一光天花晚相春。他风一年一禅花，一来一风一人。，\n",
      "loss:5.265\n",
      "愠门十英海天，，醉风就就天公。一山一人谁不花，一来一洲无公仙。一\n",
      "loss:5.244\n",
      "芒蛇下光海有天，一山编慧使崦攀。一来一风知无中，未来一年一时在。\n",
      "loss:5.184\n",
      "质榜烟踞海生筵，一山编护似天公。遥里一人无无客，一里一山天时仙。\n",
      "loss:5.140\n",
      "赊门下结接氏念，砌衍威子作天亭。一里烟头一无渡，一来风风天时心，\n",
      "loss:5.125\n",
      "渔人若光惊千垧，一步烟阁一二新。好是烟语一生里，一不渐山一时仙。\n",
      "loss:5.041\n",
      "迟人庶车六生天，砌然坚口映南中。海风一年一紫。海山一日一尧胧，海\n",
      "loss:5.021\n",
      "睹璃下路政氏妍，一来烟阁一相心。一家一教无时仙，一耳一忆细时花，\n",
      "loss:5.006\n",
      "极人驯车香于沙，一步清咏就天香。忘得一斜不无花，不来城年乐大仙，\n",
      "loss:4.923\n",
      "热门高敲斗掌念，一里犹惜紫粉苔。此知一山似清夜。一到一来一大花，\n",
      "loss:4.898\n",
      "校泉隐因接绩恙，一到罔护一知春。天是一语不无仙，未来一里初清会。\n",
      "loss:4.876\n",
      "蝴门下光剧千斗，一枝黄别万节碑。遥来一教有江仙。万到青屿三朦胧。\n",
      "loss:4.830\n",
      "骞清下结接绩韬，一儿皇花旧染霆。不年一教尽多仙，一枝一忆尚公人。\n",
      "loss:4.702\n",
      "掉鱼烟光映千，一花眷彻色本衣。洛迎一舒频公青，未来低语不紫仙。一\n",
      "loss:4.681\n",
      "味知盆粤斗恬苔，三暖呵濞吐青香。怪到一斜回等中，未及一人不无红。\n",
      "loss:4.645\n",
      "掌榜喧叟接绩宣，瘴棠先阁逐壮花。未目一年秋尧，一风一影秋尧花。一\n",
      "loss:4.631\n",
      "宴浪不光都自空，三霄涌篱似染中。一知渐山天尧花，一耳败却甚禅扉。\n",
      "loss:4.560\n",
      "兽浪何武接氏溶，一步巅税一喧藏。白知一斜一多仙，争遣烟声不云。金\n",
      "loss:4.483\n",
      "入瀛不落绶若过，扶光屈枰一转箱。木知不斜认无老，万山南幅一公仙。\n",
      "loss:4.442\n",
      "扶花风雨西盈城，一湾成阁一沈裟。赤知渐山争尧有，万鸡遥忆应钓攀。\n",
      "loss:4.378\n",
      "繁萧路树悲若沙，秋山抵贵早超纹。赤廉粗寺回卿花，回梦一忆尽江思。\n",
      "loss:4.357\n",
      "苦今觉车度罅席，一章清瓢吐成哗。青里盛藤知野径，一拳一人不老仙。\n",
      "loss:4.320\n",
      "动人风路政有天，匹须编篱作短公。一知烟教天生重，未花一树初知。一\n",
      "loss:4.236\n",
      "烝鸡远上教露猫，破醅载阁一粉莲。怒缨纡涛一丈铨，一首遥历睍伊觫。\n",
      "loss:4.130\n",
      "震璃猊床侍释迦，破意编篱作短鹅。一知不城频汉世，海瓣丛卧细卢鼗。\n",
      "loss:4.122\n",
      "溟水觉圃接巉险，郑须编篱赋领鞯。菜若纵障知野径，一鸡冈蜞天公青。\n",
      "loss:4.085\n",
      "觳得下光易画谋，匹须编篱作短屏。依酒一名桅蝴胧，一风烟洲认朦。高\n",
      "loss:4.092\n",
      "曨蛇各邦飘设险，呼门芭慧首娉婷。拂轩几人五梦句，故涛败涛拥穹扉。\n",
      "loss:3.960\n",
      "校储宝剑点当韬，砌下编山作诃诋。更条晴丑频卢仙，一刃酣榔勒心违。\n",
      "loss:3.879\n",
      "况璃猊床政鸣齩，甘弦载咏吐青眠。残来称居曾终力，此犁何此有等铨。\n",
      "loss:3.822\n",
      "堑门下光列画名，穰穰妇樯三短端。菜甲恍作饶舍急，笋吰樵劚细疑堂。\n",
      "loss:3.889\n",
      "藏门山嶕营雌伏，砌下编慕女兼枪。奚酒年造兄踵湿，更是鸟语认多德。\n",
      "loss:3.818\n",
      "寂台何社香贝叹，细步成阁现袈裟。但服矣枪痿筋力，夜时心城认锄骨。\n",
      "loss:3.685\n",
      "劚储远涎看林迈，砌绩天怪健楫哉。自教盛槎知野径，一遣幽珠不赐铨。\n",
      "loss:3.714\n",
      "沽榜喧传姓氏先，文章此阁吐诗莲。萸清年年桅城会，未及猱瑚逐觳鳄。\n",
      "loss:3.645\n",
      "船台射十六岛过，精章呵护烦落公。荡缨纡回判沙口，山风烟处尽系嘶。\n",
      "loss:3.503\n",
      "减香隐光映画安，扶门涌棹苦超纹。洛轩纵幻黄渺小，万遣丛轧呕池力。\n",
      "loss:3.571\n",
      "暨里灰车天绩宣，金儿绛属乌鹊嚣。片来偏沌无难成，一者一香不独。不\n",
      "loss:3.448\n",
      "误门下车政绩宣，甘棠载豹落沧鸣。百青盛藤知虞供，秫吰图锐几染嗷。\n",
      "loss:3.404\n",
      "语台三畴耕凿险，羲然盛壁逃中熇。长来一毛喷黄好，官花一层几藩麾。\n",
      "loss:3.430\n",
      "璈字宝剑挥牛刀，遮棠载咏吐青香。怪是揽辔知公滑，衣问庭浆一瞬星。\n",
      "loss:3.382\n",
      "舂迷攒集乡可恙，一儿扬累海顷君。岁啖蛎萸童无径，一鸡刊瘴尽灾心。\n",
      "loss:3.285\n",
      "青耳环绕木天宽，何载傀寒遍夕犀。海年不树谁颗虎，栽括涛莽未尧筹。\n",
      "loss:3.316\n",
      "嚼鱼宝割挥无香，砌碎轩轩一粉齑。天亭握枪凭忠裕，秫鞭未劚尚云青。\n",
      "loss:3.255\n",
      "肠门罗光列自名，软穰针拍烦天公。荡目枯离迷敷治，不常丛静一滕尝。\n",
      "loss:3.118\n",
      "门有灞彩惟恃险，熙下一饱志天膏。海到绝哥持儒綯，不臣盟竹脍春云。\n",
      "loss:3.118\n",
      "旅得庶草并可夸，枝味跳舞又鸿英。酋路内引禾葡萄，秫陌杂死挛春听。\n",
      "loss:3.042\n",
      "彩门花结驾上垧，赤瀑载香报监中。标标引藤知公志，愿陌杂尽挛腰脐。\n",
      "loss:3.052\n",
      "蚝浪居晴上鸣豪，噫仔芒瑚使儿鲜。一飘栉枪调最滑，小争同问面玉金。\n",
      "loss:2.982\n",
      "沽门下光映玉斗，穰玉天兽费岁罗。荡曦汉仆惟雕饰，称窜应年一等铨。\n",
      "loss:3.105\n",
      "沧花云光麋西缫，踏山富贵旧印纹。伏阳几有随野意，一枝熏然难双青。\n",
      "loss:3.072\n",
      "扫兢捧檄看瀛堧，红垒烟咏一芙蓉。澄清揽郁知公志，愿得弼时重仔肩。\n",
      "loss:2.932\n",
      "闽峰何阮溯去程，红槎岂阁下须尘。海是盛德花敷治，海鸡相人铸樊人。\n",
      "loss:2.878\n",
      "攸兢喧檄渡瀛堧，。家没火火殄笔端。吟到日斜清兴在，万竿丛竹勒春墙\n",
      "loss:2.876\n",
      "蛾箐直踞渡尺家，遗舶樊笼种锡茅。报独浡作成泽国，笋鞭未劚尚留青。\n",
      "loss:2.776\n",
      "面蛇腻光乡余森，海然绛骚苦嚣哉。青阁歧竹来齿，不犁秋采禅昔贤。夜\n",
      "loss:2.710\n",
      "皇开三畴耕凿易，欣然醉饱乐象虞。饱目枯仅知时脯，蛮乡放竹勒春花。\n",
      "loss:2.657\n",
      "擎鼓波武踪尺伏，估舶轩阴学舞栽。怒清揽辔辛勤裕蛮，海供滋雁醒觳贤\n",
      "loss:2.603\n",
      "酿和高构接林迈，砌下编德作短屏。菜甲初舒频染绿，笋鞭未劚尚留青。\n",
      "loss:2.587\n",
      "尤门烟星八鼓宣，鲤棠筵拍入飞槎。饱懒冰回妇巨急，一诸北香弱故香。\n",
      "loss:2.531\n",
      "脐璃案集都万新，朝鸟眷别受卷毫。走舆当有看野渡，争雄壁垒几沧妇。\n",
      "loss:2.469\n",
      "结钧莫推陈斜向，望岭何荣届行帏。一前海居山拋小，故得遥望寸气违。\n",
      "loss:2.437\n",
      "潜西腻气量余粟，送有异德黄深狡。散来岛道锦黑地，春家心验刺园猿。\n",
      "loss:2.471\n",
      "声本由人性自天，功名初定鲎子溟。虎鲨当数惟无笑，畅所如此傍尧天。\n",
      "loss:2.473\n",
      "乂里高成耸玉练，我阑花银悦监衔。中城眼圃回济后，故遣当瓠细音诗。\n",
      "loss:2.422\n",
      "借却十阮锁繁空，井势犹花色短屏。菜甲初舒频染绿，笋鞭未劚尚留青。\n",
      "loss:2.321\n",
      "旭榜喧传姓氏先，文章台阁吐青莲。海是任德漫犬小，涸鳞杂尽挛城贤。\n",
      "loss:2.274\n",
      "营后狙犷斗恬熙，呼弦羞惯白桅蓉。但乳烟芥托官澜，博更荒时那凡禽。\n",
      "loss:2.274\n",
      "巅得未车政绩宣，甘棠载咏入诗篇。澄清日尔清兴处，一亩北岸野盈家。\n",
      "loss:2.298\n",
      "石头形骸诛封豕，呼光异娥旧印纹。沙阳矶头客腊重，笔龙佳诚贯海虹。\n",
      "loss:2.274\n",
      "迷萧风近心隐隐，暗歌闲译疑山新。作到神逋征藩鹊，潮臣鸿雁一虫黎。\n",
      "loss:2.419\n",
      "鳌身贔屭拄坤轴，羲毂轩轩一家輠。澄清揽辔行公志，愿更篇时重仔肩。\n",
      "loss:2.392\n",
      "罩香走马到萧篱，芒仔珊瑚茄落琴。清也逢翁驱奴鹊，凉类长难争日眠。\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_poetry_acrostic() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bdf442238928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"loss:{loss:.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_poetry_auto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mgenerate_poetry_acrostic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: generate_poetry_acrostic() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    all_data, (w1, word_2_index, index_2_word) = train_vec(train_num=300)\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    lr = 0.01\n",
    "    hidden_num = 128\n",
    "    word_size, embedding_num = w1.shape\n",
    "\n",
    "    dataset = Poetry_Dataset(w1, word_2_index, all_data)\n",
    "    dataloader = DataLoader(dataset, batch_size)\n",
    "\n",
    "    model = Poetry_Model_lstm(hidden_num, word_size, embedding_num)\n",
    "    model = model.to(model.device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for batch_index, (batch_x_embedding, batch_y_index) in enumerate(dataloader):\n",
    "            model.train()\n",
    "            batch_x_embedding = batch_x_embedding.to(model.device)\n",
    "            batch_y_index = batch_y_index.to(model.device)\n",
    "\n",
    "            #模型预测\n",
    "            \n",
    "            \n",
    "            #计算损失\n",
    "            \n",
    "\n",
    "            # 梯度反传 , 梯度累加, 但梯度并不更新, 梯度是由优化器更新的\n",
    "            \n",
    "            \n",
    "            # 使用优化器更新梯度\n",
    "            \n",
    "            \n",
    "            # 梯度清零\n",
    "               \n",
    "            \n",
    "\n",
    "            if batch_index % 100 == 0:\n",
    "                # model.eval()\n",
    "                print(f\"loss:{loss:.3f}\")\n",
    "                print(generate_poetry_auto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7552262",
   "metadata": {},
   "outputs": [],
   "source": [
    "描述一下你的模型："
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl_pt",
   "language": "python",
   "name": "nndl_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
